{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Deap.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3NQ5D6f8xZV",
        "outputId": "da7b23f4-1c33-4092-c219-d47509597895"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mNV4C3a9V6a",
        "outputId": "7501df12-b643-4990-ea89-22661c92b794"
      },
      "source": [
        "pip install git+https://github.com/forrestbao/pyeeg.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/forrestbao/pyeeg.git\n",
            "  Cloning https://github.com/forrestbao/pyeeg.git to /tmp/pip-req-build-88l8fw6i\n",
            "  Running command git clone -q https://github.com/forrestbao/pyeeg.git /tmp/pip-req-build-88l8fw6i\n",
            "Requirement already satisfied (use --upgrade to upgrade): pyeeg==0.4.4 from git+https://github.com/forrestbao/pyeeg.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyeeg==0.4.4) (1.16.1)\n",
            "Building wheels for collected packages: pyeeg\n",
            "  Building wheel for pyeeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28121 sha256=4fb1291c71dcff1357805f116267211c6af3194b2c9c71d222908b8198f2e44d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ds_q67o4/wheels/2d/3f/ad/106d4fc80b61d1ea1fc18e76e7439fd98aa043d83d58eae741\n",
            "Successfully built pyeeg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SIrPxvHm-JC",
        "outputId": "bca2f33b-b438-4d7e-b3cb-4c6fc8e1d1fa"
      },
      "source": [
        "!pip install numpy==1.16.1\n",
        "#import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (1.16.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nLMDbCJX8VF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fupwT213JlB_"
      },
      "source": [
        "import numpy as np\n",
        "import pyeeg as pe\n",
        "import pickle as pickle\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrSxWVL7JlB_"
      },
      "source": [
        "#channel = [1,2,3,4,6,11,13,17,19,20,21,25,29,31] #15 Channels chosen to fit Emotiv Epoch+\n",
        "channel = [1,2,4,5,8,10,15,21,22,25,26,27,28,31,32]\n",
        "band = [4,8,13,22,30,45] #5 bands\n",
        "window_size = 256 #Averaging band power of 2 sec\n",
        "step_size = 16 #Each 0.125 sec update once\n",
        "sample_rate = 128 #Sampling rate of 128 Hz\n",
        "subjectList = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32']\n",
        "\n",
        "#List of subjects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2mOXPtxJlB_"
      },
      "source": [
        "def FFT_Processing (sub, channel, band, window_size, step_size, sample_rate):\n",
        "    '''\n",
        "    arguments:  string subject\n",
        "                list channel indice\n",
        "                list band\n",
        "                int window size for FFT\n",
        "                int step size for FFT\n",
        "                int sample rate for FFT\n",
        "    return:     void\n",
        "    '''\n",
        "    meta = []\n",
        "    with open('/content/drive/MyDrive/MTech_Project/data_preprocessed_python/s' + sub + '.dat', 'rb') as file:\n",
        "\n",
        "        subject = pickle.load(file, encoding='latin1') #resolve the python 2 data problem by encoding : latin1\n",
        "\n",
        "        for i in range (0,40):\n",
        "            # loop over 0-39 trails\n",
        "            data = subject[\"data\"][i]\n",
        "            labels = subject[\"labels\"][i]\n",
        "            start = 0;\n",
        "            #data.shape\n",
        "\n",
        "            while start + window_size < data.shape[1]:\n",
        "                meta_array = []\n",
        "                meta_data = [] #meta vector for analysis\n",
        "                for j in channel:\n",
        "                    X = data[j][start : start + window_size] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
        "                    Y = pe.bin_power(X, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
        "                    meta_data = meta_data + list(Y[0])\n",
        "\n",
        "                meta_array.append(np.array(meta_data))\n",
        "                meta_array.append(labels)\n",
        "\n",
        "                meta.append(np.array(meta_array))    \n",
        "                start = start + step_size\n",
        "                \n",
        "        meta = np.array(meta)\n",
        "        np.save('/content/drive/MyDrive/MTech_Project/processed_DEAP/s' + sub, meta, allow_pickle=True, fix_imports=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaIb2ByPJlCA"
      },
      "source": [
        "for subjects in subjectList:\n",
        "    FFT_Processing (subjects, channel, band, window_size, step_size, sample_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZW1VR9yJlCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b75e3d4-bc3d-4aef-8d5d-857e464eddcd"
      },
      "source": [
        "data_training = []\n",
        "label_training = []\n",
        "data_testing = []\n",
        "label_testing = []\n",
        "\n",
        "# save np.load\n",
        "#np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "#np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "for subjects in subjectList:\n",
        "\n",
        "    with open('/content/drive/MyDrive/MTech_Project/processed_DEAP/s' + subjects + '.npy', 'rb') as file:\n",
        "        sub = np.load(file)\n",
        "        for i in range (0,sub.shape[0]):\n",
        "            #print(sub.shape[0])\n",
        "            if i % 8 == 0:\n",
        "                #print(\"hey\")\n",
        "                #print(sub[i][0])\n",
        "                data_testing.append(sub[i][0])\n",
        "                label_testing.append(sub[i][1])\n",
        "            else:\n",
        "                data_training.append(sub[i][0])\n",
        "                label_training.append(sub[i][1])\n",
        "\n",
        "# restore np.load for future normal usage\n",
        "#np.load = np_load_old\n",
        "\n",
        "np.save('/content/drive/MyDrive/MTech_Project/data_training/data_training', np.array(data_training), allow_pickle=True, fix_imports=True)\n",
        "np.save('/content/drive/MyDrive/MTech_Project/label_training/label_training', np.array(label_training), allow_pickle=True, fix_imports=True)\n",
        "print(\"training dataset:\", np.array(data_training).shape, np.array(label_training).shape)\n",
        "\n",
        "np.save('/content/drive/MyDrive/MTech_Project/data_testing/data_testing', np.array(data_testing), allow_pickle=True, fix_imports=True)\n",
        "np.save('/content/drive/MyDrive/MTech_Project/label_testing/label_testing', np.array(label_testing), allow_pickle=True, fix_imports=True)\n",
        "print(\"testing dataset:\", np.array(data_testing).shape, np.array(label_testing).shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training dataset: (85400, 75) (85400, 4)\n",
            "testing dataset: (12200, 75) (12200, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mchn2TPLJlCA"
      },
      "source": [
        "with open('/content/drive/MyDrive/MTech_Project/data_training/data_training.npy', 'rb') as fileTrain:\n",
        "    X  = np.load(fileTrain)\n",
        "    \n",
        "with open('/content/drive/MyDrive/MTech_Project/label_training/label_training.npy', 'rb') as fileTrainL:\n",
        "    Y  = np.load(fileTrainL)\n",
        "    \n",
        "X = normalize(X)\n",
        "Z = np.ravel(Y[:, [1]])\n",
        "\n",
        "Arousal_Train = np.ravel(Y[:, [0]])\n",
        "Valence_Train = np.ravel(Y[:, [1]])\n",
        "Domain_Train = np.ravel(Y[:, [2]])\n",
        "Like_Train = np.ravel(Y[:, [3]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGxbBUCDJlCA"
      },
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical \n",
        "from keras.layers import Dense, Dropout, Flatten, MaxPooling2D\n",
        "from keras.models import Model\n",
        "import timeit\n",
        "from keras.layers.convolutional import MaxPooling1D, ZeroPadding1D\n",
        "from keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z55_-2v6JlCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016b3f19-561b-422d-f001-fda3f7fb33d4"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(Z)\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A5H1uvlJlCB"
      },
      "source": [
        "x_train = np.array(X[:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIfiikatJlCB"
      },
      "source": [
        "with open('/content/drive/MyDrive/MTech_Project/data_testing/data_testing.npy', 'rb') as fileTrain:\n",
        "    M  = np.load(fileTrain)\n",
        "    \n",
        "with open('/content/drive/MyDrive/MTech_Project/label_testing/label_testing.npy', 'rb') as fileTrainL:\n",
        "    N  = np.load(fileTrainL)\n",
        "\n",
        "M = normalize(M)\n",
        "L = np.ravel(N[:, [1]])\n",
        "\n",
        "Arousal_Test = np.ravel(N[:, [0]])\n",
        "Valence_Test = np.ravel(N[:, [1]])\n",
        "Domain_Test = np.ravel(N[:, [2]])\n",
        "Like_Test = np.ravel(N[:, [3]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXYrxe6oJlCB"
      },
      "source": [
        "x_test = np.array(M[:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Gva1_rJlCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1a1eee-1b11-454b-9c7d-967a41ae379a"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_test = to_categorical(L)\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pzf0OhtJlCB"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.fit_transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A-iZ57fJlCB"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1], 1)\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF2jcHDSJlCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04ee1a4-97ee-4b19-f677-26e1d19995fe"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85400, 75, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MfMfglfJlCC"
      },
      "source": [
        "batch_size = 256\n",
        "num_classes = 10\n",
        "epochs = 200\n",
        "input_shape=(x_train.shape[1], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XQUrEmvJlCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147d3e41-53a5-498b-aa67-405857876d2c"
      },
      "source": [
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6--0z39WJlCC"
      },
      "source": [
        "from keras.layers import Convolution1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten, Dense\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB-5C_qLJlCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c062ea5b-fa8f-4619-aede-7880575d8adf"
      },
      "source": [
        "model = Sequential()\n",
        "intput_shape=(x_train.shape[1], 1)\n",
        "model.add(Conv1D(128, kernel_size=3,padding = 'same',activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Conv1D(128,kernel_size=3,padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "#model.add(Conv1D(64,kernel_size=3,padding = 'same', activation='relu'))\n",
        "#model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_6 (Conv1D)            (None, 75, 128)           512       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 75, 128)           512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 37, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 37, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 37, 128)           512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                147520    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 201,114\n",
            "Trainable params: 200,602\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yy3SyqQJlCC"
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dhES6KfJlCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18688411-d798-45e9-e43f-58645aaf2cf9"
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 2.0534 - accuracy: 0.2383\n",
            "Epoch 2/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.8941 - accuracy: 0.2822\n",
            "Epoch 3/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.8146 - accuracy: 0.3135\n",
            "Epoch 4/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.7526 - accuracy: 0.3371\n",
            "Epoch 5/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.6987 - accuracy: 0.3591\n",
            "Epoch 6/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.6488 - accuracy: 0.3784\n",
            "Epoch 7/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.6058 - accuracy: 0.3964\n",
            "Epoch 8/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.5605 - accuracy: 0.4154\n",
            "Epoch 9/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.5160 - accuracy: 0.4340\n",
            "Epoch 10/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.4709 - accuracy: 0.4538\n",
            "Epoch 11/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.4368 - accuracy: 0.4666\n",
            "Epoch 12/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.3959 - accuracy: 0.4865\n",
            "Epoch 13/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.3650 - accuracy: 0.4981\n",
            "Epoch 14/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.3262 - accuracy: 0.5135\n",
            "Epoch 15/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.3017 - accuracy: 0.5239\n",
            "Epoch 16/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.2723 - accuracy: 0.5352\n",
            "Epoch 17/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.2482 - accuracy: 0.5457\n",
            "Epoch 18/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.2252 - accuracy: 0.5536\n",
            "Epoch 19/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.2069 - accuracy: 0.5604\n",
            "Epoch 20/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.1873 - accuracy: 0.5679\n",
            "Epoch 21/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.1586 - accuracy: 0.5796\n",
            "Epoch 22/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.1494 - accuracy: 0.5819\n",
            "Epoch 23/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.1297 - accuracy: 0.5891\n",
            "Epoch 24/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.1213 - accuracy: 0.5940\n",
            "Epoch 25/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.0986 - accuracy: 0.6019\n",
            "Epoch 26/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.0919 - accuracy: 0.6054\n",
            "Epoch 27/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.0725 - accuracy: 0.6120\n",
            "Epoch 28/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.0625 - accuracy: 0.6169\n",
            "Epoch 29/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.0542 - accuracy: 0.6199\n",
            "Epoch 30/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.0469 - accuracy: 0.6231\n",
            "Epoch 31/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.0345 - accuracy: 0.6270\n",
            "Epoch 32/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.0207 - accuracy: 0.6308\n",
            "Epoch 33/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 1.0114 - accuracy: 0.6361\n",
            "Epoch 34/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9998 - accuracy: 0.6401\n",
            "Epoch 35/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9952 - accuracy: 0.6432\n",
            "Epoch 36/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9815 - accuracy: 0.6484\n",
            "Epoch 37/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9772 - accuracy: 0.6502\n",
            "Epoch 38/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9707 - accuracy: 0.6515\n",
            "Epoch 39/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9668 - accuracy: 0.6553\n",
            "Epoch 40/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9554 - accuracy: 0.6575\n",
            "Epoch 41/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9482 - accuracy: 0.6606\n",
            "Epoch 42/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9421 - accuracy: 0.6623\n",
            "Epoch 43/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9341 - accuracy: 0.6663\n",
            "Epoch 44/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9309 - accuracy: 0.6690\n",
            "Epoch 45/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9201 - accuracy: 0.6738\n",
            "Epoch 46/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9189 - accuracy: 0.6725\n",
            "Epoch 47/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9103 - accuracy: 0.6757\n",
            "Epoch 48/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.9055 - accuracy: 0.6783\n",
            "Epoch 49/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8973 - accuracy: 0.6806\n",
            "Epoch 50/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8881 - accuracy: 0.6835\n",
            "Epoch 51/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8826 - accuracy: 0.6856\n",
            "Epoch 52/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8754 - accuracy: 0.6882\n",
            "Epoch 53/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8769 - accuracy: 0.6899\n",
            "Epoch 54/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8759 - accuracy: 0.6876\n",
            "Epoch 55/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8636 - accuracy: 0.6944\n",
            "Epoch 56/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8653 - accuracy: 0.6935\n",
            "Epoch 57/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8535 - accuracy: 0.6980\n",
            "Epoch 58/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8537 - accuracy: 0.6980\n",
            "Epoch 59/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8428 - accuracy: 0.7020\n",
            "Epoch 60/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8449 - accuracy: 0.6995\n",
            "Epoch 61/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8411 - accuracy: 0.7024\n",
            "Epoch 62/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8350 - accuracy: 0.7046\n",
            "Epoch 63/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8305 - accuracy: 0.7063\n",
            "Epoch 64/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8223 - accuracy: 0.7086\n",
            "Epoch 65/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8269 - accuracy: 0.7063\n",
            "Epoch 66/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8222 - accuracy: 0.7084\n",
            "Epoch 67/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8216 - accuracy: 0.7079\n",
            "Epoch 68/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8143 - accuracy: 0.7128\n",
            "Epoch 69/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8080 - accuracy: 0.7140\n",
            "Epoch 70/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8043 - accuracy: 0.7163\n",
            "Epoch 71/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.8023 - accuracy: 0.7168\n",
            "Epoch 72/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7965 - accuracy: 0.7187\n",
            "Epoch 73/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7990 - accuracy: 0.7175\n",
            "Epoch 74/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7925 - accuracy: 0.7199\n",
            "Epoch 75/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7887 - accuracy: 0.7203\n",
            "Epoch 76/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7873 - accuracy: 0.7207\n",
            "Epoch 77/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7773 - accuracy: 0.7252\n",
            "Epoch 78/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7786 - accuracy: 0.7244\n",
            "Epoch 79/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7699 - accuracy: 0.7274\n",
            "Epoch 80/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7714 - accuracy: 0.7293\n",
            "Epoch 81/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7700 - accuracy: 0.7277\n",
            "Epoch 82/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7665 - accuracy: 0.7286\n",
            "Epoch 83/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7623 - accuracy: 0.7314\n",
            "Epoch 84/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7562 - accuracy: 0.7336\n",
            "Epoch 85/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7531 - accuracy: 0.7335\n",
            "Epoch 86/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7537 - accuracy: 0.7326\n",
            "Epoch 87/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7503 - accuracy: 0.7358\n",
            "Epoch 88/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7493 - accuracy: 0.7352\n",
            "Epoch 89/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7524 - accuracy: 0.7358\n",
            "Epoch 90/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7497 - accuracy: 0.7353\n",
            "Epoch 91/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7386 - accuracy: 0.7399\n",
            "Epoch 92/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7337 - accuracy: 0.7418\n",
            "Epoch 93/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7380 - accuracy: 0.7406\n",
            "Epoch 94/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7400 - accuracy: 0.7393\n",
            "Epoch 95/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7337 - accuracy: 0.7408\n",
            "Epoch 96/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7300 - accuracy: 0.7426\n",
            "Epoch 97/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7324 - accuracy: 0.7434\n",
            "Epoch 98/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7279 - accuracy: 0.7438\n",
            "Epoch 99/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7275 - accuracy: 0.7452\n",
            "Epoch 100/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7300 - accuracy: 0.7439\n",
            "Epoch 101/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7162 - accuracy: 0.7467\n",
            "Epoch 102/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7179 - accuracy: 0.7475\n",
            "Epoch 103/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7213 - accuracy: 0.7459\n",
            "Epoch 104/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7168 - accuracy: 0.7498\n",
            "Epoch 105/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7087 - accuracy: 0.7499\n",
            "Epoch 106/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7124 - accuracy: 0.7503\n",
            "Epoch 107/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7020 - accuracy: 0.7532\n",
            "Epoch 108/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7070 - accuracy: 0.7519\n",
            "Epoch 109/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7056 - accuracy: 0.7519\n",
            "Epoch 110/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6988 - accuracy: 0.7547\n",
            "Epoch 111/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7034 - accuracy: 0.7523\n",
            "Epoch 112/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6953 - accuracy: 0.7539\n",
            "Epoch 113/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6910 - accuracy: 0.7562\n",
            "Epoch 114/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.7012 - accuracy: 0.7527\n",
            "Epoch 115/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6923 - accuracy: 0.7569\n",
            "Epoch 116/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6956 - accuracy: 0.7551\n",
            "Epoch 117/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6882 - accuracy: 0.7574\n",
            "Epoch 118/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6922 - accuracy: 0.7573\n",
            "Epoch 119/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6789 - accuracy: 0.7615\n",
            "Epoch 120/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6833 - accuracy: 0.7589\n",
            "Epoch 121/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6832 - accuracy: 0.7600\n",
            "Epoch 122/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6863 - accuracy: 0.7597\n",
            "Epoch 123/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6795 - accuracy: 0.7622\n",
            "Epoch 124/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6787 - accuracy: 0.7618\n",
            "Epoch 125/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6707 - accuracy: 0.7643\n",
            "Epoch 126/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6746 - accuracy: 0.7635\n",
            "Epoch 127/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6708 - accuracy: 0.7640\n",
            "Epoch 128/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6745 - accuracy: 0.7633\n",
            "Epoch 129/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6687 - accuracy: 0.7643\n",
            "Epoch 130/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6677 - accuracy: 0.7649\n",
            "Epoch 131/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6685 - accuracy: 0.7643\n",
            "Epoch 132/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6583 - accuracy: 0.7679\n",
            "Epoch 133/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6629 - accuracy: 0.7659\n",
            "Epoch 134/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6641 - accuracy: 0.7672\n",
            "Epoch 135/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6585 - accuracy: 0.7692\n",
            "Epoch 136/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6596 - accuracy: 0.7688\n",
            "Epoch 137/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6514 - accuracy: 0.7721\n",
            "Epoch 138/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6577 - accuracy: 0.7700\n",
            "Epoch 139/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6544 - accuracy: 0.7712\n",
            "Epoch 140/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6512 - accuracy: 0.7698\n",
            "Epoch 141/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6546 - accuracy: 0.7709\n",
            "Epoch 142/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6495 - accuracy: 0.7710\n",
            "Epoch 143/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.7701\n",
            "Epoch 144/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6444 - accuracy: 0.7737\n",
            "Epoch 145/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6434 - accuracy: 0.7747\n",
            "Epoch 146/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6477 - accuracy: 0.7741\n",
            "Epoch 147/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6386 - accuracy: 0.7762\n",
            "Epoch 148/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6419 - accuracy: 0.7748\n",
            "Epoch 149/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6310 - accuracy: 0.7786\n",
            "Epoch 150/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6406 - accuracy: 0.7747\n",
            "Epoch 151/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6332 - accuracy: 0.7787\n",
            "Epoch 152/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6441 - accuracy: 0.7749\n",
            "Epoch 153/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6325 - accuracy: 0.7769\n",
            "Epoch 154/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6361 - accuracy: 0.7775\n",
            "Epoch 155/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6251 - accuracy: 0.7814\n",
            "Epoch 156/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6330 - accuracy: 0.7783\n",
            "Epoch 157/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6321 - accuracy: 0.7779\n",
            "Epoch 158/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6319 - accuracy: 0.7782\n",
            "Epoch 159/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6316 - accuracy: 0.7780\n",
            "Epoch 160/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6272 - accuracy: 0.7799\n",
            "Epoch 161/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6288 - accuracy: 0.7785\n",
            "Epoch 162/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6194 - accuracy: 0.7831\n",
            "Epoch 163/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6194 - accuracy: 0.7818\n",
            "Epoch 164/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6236 - accuracy: 0.7823\n",
            "Epoch 165/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6214 - accuracy: 0.7827\n",
            "Epoch 166/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6198 - accuracy: 0.7829\n",
            "Epoch 167/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6152 - accuracy: 0.7835\n",
            "Epoch 168/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6190 - accuracy: 0.7833\n",
            "Epoch 169/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6106 - accuracy: 0.7862\n",
            "Epoch 170/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6090 - accuracy: 0.7865\n",
            "Epoch 171/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6100 - accuracy: 0.7855\n",
            "Epoch 172/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6122 - accuracy: 0.7839\n",
            "Epoch 173/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6092 - accuracy: 0.7870\n",
            "Epoch 174/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6130 - accuracy: 0.7853\n",
            "Epoch 175/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6063 - accuracy: 0.7878\n",
            "Epoch 176/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6071 - accuracy: 0.7883\n",
            "Epoch 177/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6030 - accuracy: 0.7892\n",
            "Epoch 178/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6011 - accuracy: 0.7889\n",
            "Epoch 179/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6092 - accuracy: 0.7867\n",
            "Epoch 180/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6020 - accuracy: 0.7894\n",
            "Epoch 181/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5996 - accuracy: 0.7909\n",
            "Epoch 182/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5990 - accuracy: 0.7907\n",
            "Epoch 183/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6028 - accuracy: 0.7886\n",
            "Epoch 184/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6076 - accuracy: 0.7861\n",
            "Epoch 185/200\n",
            "334/334 [==============================] - 3s 10ms/step - loss: 0.6008 - accuracy: 0.7906\n",
            "Epoch 186/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6022 - accuracy: 0.7905\n",
            "Epoch 187/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.6024 - accuracy: 0.7882\n",
            "Epoch 188/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5903 - accuracy: 0.7927\n",
            "Epoch 189/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5965 - accuracy: 0.7913\n",
            "Epoch 190/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5927 - accuracy: 0.7935\n",
            "Epoch 191/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5995 - accuracy: 0.7911\n",
            "Epoch 192/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5962 - accuracy: 0.7905\n",
            "Epoch 193/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5911 - accuracy: 0.7934\n",
            "Epoch 194/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5888 - accuracy: 0.7936\n",
            "Epoch 195/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5933 - accuracy: 0.7925\n",
            "Epoch 196/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5903 - accuracy: 0.7933\n",
            "Epoch 197/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5835 - accuracy: 0.7941\n",
            "Epoch 198/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5847 - accuracy: 0.7951\n",
            "Epoch 199/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5851 - accuracy: 0.7959\n",
            "Epoch 200/200\n",
            "334/334 [==============================] - 3s 8ms/step - loss: 0.5805 - accuracy: 0.7957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "v6ck84Ko_UNj",
        "outputId": "dd1584dd-f27e-4149-f4ac-86c41e89e7f2"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\r\n",
        "plt.plot(history.history['loss'], label = 'loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.ylim([0.5, 1])\r\n",
        "plt.legend(loc='Upper right')\r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "382/382 [==============================] - 1s 2ms/step - loss: 0.7430 - accuracy: 0.7961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WItRwjQz05BI",
        "outputId": "0f14cd76-7b8e-45ed-842a-569e404ab974"
      },
      "source": [
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.6190317273139954\n",
            "Test accuracy: 0.8084426522254944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruUlU0AZFydV"
      },
      "source": [
        "A = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdf41L-QF1pI",
        "outputId": "1e85591b-7277-4f60-d552-cf58ed922263"
      },
      "source": [
        "A[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.9104124e-32, 5.4737509e-05, 1.6035015e-03, 2.5269753e-04,\n",
              "       5.7713358e-05, 5.2189794e-06, 6.2019960e-04, 9.9549770e-01,\n",
              "       1.8632810e-03, 4.4945878e-05], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f-SZw_HGihz",
        "outputId": "b89abe1a-6b78-44e8-e42b-a857b86df978"
      },
      "source": [
        "np.round(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    }
  ]
}